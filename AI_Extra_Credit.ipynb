{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from SourceCode import MancalaGameAI\n",
    "import numpy as np\n",
    "random.seed(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPlayer:\n",
    "    def get_move(self, state):\n",
    "        return state.random_move_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------- AlphaBeta --------------------\n",
    "def alpha_beta_cutoff_search(state, game, d, cutoff_test=None, eval_fn=None):\n",
    "    #Search game to determine best action; use alpha-beta pruning.\n",
    "    #This version cuts off sTearch and uses an evaluation function.\n",
    "    player = game.to_move(state)\n",
    "\n",
    "    # Functions used by alpha_beta\n",
    "    def max_value(state, alpha, beta, depth):\n",
    "        if cutoff_test(state, depth):\n",
    "            return eval_fn(state)\n",
    "        v = -np.inf\n",
    "        for a in game.actions(state):\n",
    "            v = max(v, min_value(game.result(state, a), alpha, beta, depth + 1))\n",
    "            if v >= beta:\n",
    "                return v\n",
    "            alpha = max(alpha, v)\n",
    "        return v\n",
    "\n",
    "    def min_value(state, alpha, beta, depth):\n",
    "        if cutoff_test(state, depth):\n",
    "            return eval_fn(state)\n",
    "        v = np.inf\n",
    "        for a in game.actions(state):\n",
    "            v = min(v, max_value(game.result(state, a), alpha, beta, depth + 1))\n",
    "            if v <= alpha:\n",
    "                return v\n",
    "            beta = min(beta, v)\n",
    "        return v\n",
    "\n",
    "    # Body of alpha_beta_cutoff_search starts here:\n",
    "    # The default test cuts off at depth d or at a terminal state\n",
    "    cutoff_test = (cutoff_test or (lambda state, depth: depth > d or game.terminal_test(state)))\n",
    "    eval_fn = eval_fn or (lambda state: game.utility2(state, player))\n",
    "    best_score = -np.inf\n",
    "    beta = np.inf\n",
    "    best_action = None\n",
    "    for a in game.actions(state):\n",
    "        v = min_value(game.result(state, a), best_score, beta, 1)\n",
    "        if v > best_score:\n",
    "            best_score = v\n",
    "            best_action = a\n",
    "    return best_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI player using Alpha-Beta Pruning\n",
    "class AlphaBetaAI:\n",
    "    def __init__(self, depth):\n",
    "        self.depth = depth\n",
    "        self.game_adapter = MancalaGameAI()\n",
    "\n",
    "    def get_move(self, state):\n",
    "        return alpha_beta_cutoff_search(state, self.game_adapter, d=self.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game_AI(ai_player, opponent):\n",
    "    game = MancalaGameAI()\n",
    "    \n",
    "    state = game.initial\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "    while not game.terminal_test(state):\n",
    "        # game.display(state)\n",
    "        if game.to_move(state) == 1:\n",
    "            move = ai_player.get_move(state)\n",
    "        else:\n",
    "            move = opponent.get_move(state)\n",
    "        state = game.result(state, move)\n",
    "        count += 0.5\n",
    "\n",
    "    # game.display(state)\n",
    "    winner_score = game.utility(state, 1)\n",
    "    if winner_score > 0:\n",
    "        # print(\"AI wins\")\n",
    "        return 1, count\n",
    "    elif winner_score < 0:\n",
    "        # print(\"Opponent wins\")\n",
    "        return 2, count\n",
    "    else:\n",
    "        # print(\"Tie\")\n",
    "        return 0, count\n",
    "    \n",
    "    # Simulate 100 games\n",
    "def sim_games_AlphaBeta(num_games):\n",
    "    ai_player = AlphaBetaAI(depth=10)\n",
    "    random_player = RandomPlayer()\n",
    "    \n",
    "    ai_wins = 0\n",
    "    random_wins = 0\n",
    "    ties = 0\n",
    "    tot_turns = 0\n",
    "    \n",
    "    for i in range(num_games):\n",
    "        result, turns = play_game_AI(ai_player, random_player)\n",
    "        tot_turns += turns\n",
    "        \n",
    "        if result == 1:\n",
    "            ai_wins += 1\n",
    "        elif result == 2:\n",
    "            random_wins += 1\n",
    "        else:\n",
    "            ties += 1\n",
    "        print(\"Game \", i+1)\n",
    "    \n",
    "    print(\"Alpha-Beta AI vs Random Player\\n\")\n",
    "    print(f\"AI Wins: {ai_wins}\")\n",
    "    print(f\"Random Player Wins: {random_wins}\")\n",
    "    print(f\"Ties: {ties}\")\n",
    "    print(f\"Average Turns: {tot_turns/num_games:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game  1\n",
      "Game  2\n",
      "Game  3\n",
      "Game  4\n",
      "Game  5\n",
      "Game  6\n",
      "Game  7\n",
      "Game  8\n",
      "Game  9\n",
      "Game  10\n",
      "Game  11\n",
      "Game  12\n",
      "Game  13\n",
      "Game  14\n",
      "Game  15\n",
      "Game  16\n",
      "Game  17\n",
      "Game  18\n",
      "Game  19\n",
      "Game  20\n",
      "Game  21\n",
      "Game  22\n",
      "Game  23\n",
      "Game  24\n",
      "Game  25\n",
      "Game  26\n",
      "Game  27\n",
      "Game  28\n",
      "Game  29\n",
      "Game  30\n",
      "Game  31\n",
      "Game  32\n",
      "Game  33\n",
      "Game  34\n",
      "Game  35\n",
      "Game  36\n",
      "Game  37\n",
      "Game  38\n",
      "Game  39\n",
      "Game  40\n",
      "Game  41\n",
      "Game  42\n",
      "Game  43\n",
      "Game  44\n",
      "Game  45\n",
      "Game  46\n",
      "Game  47\n",
      "Game  48\n",
      "Game  49\n",
      "Game  50\n",
      "Game  51\n",
      "Game  52\n",
      "Game  53\n",
      "Game  54\n",
      "Game  55\n",
      "Game  56\n",
      "Game  57\n",
      "Game  58\n",
      "Game  59\n",
      "Game  60\n",
      "Game  61\n",
      "Game  62\n",
      "Game  63\n",
      "Game  64\n",
      "Game  65\n",
      "Game  66\n",
      "Game  67\n",
      "Game  68\n",
      "Game  69\n",
      "Game  70\n",
      "Game  71\n",
      "Game  72\n",
      "Game  73\n",
      "Game  74\n",
      "Game  75\n",
      "Game  76\n",
      "Game  77\n",
      "Game  78\n",
      "Game  79\n",
      "Game  80\n",
      "Game  81\n",
      "Game  82\n",
      "Game  83\n",
      "Game  84\n",
      "Game  85\n",
      "Game  86\n",
      "Game  87\n",
      "Game  88\n",
      "Game  89\n",
      "Game  90\n",
      "Game  91\n",
      "Game  92\n",
      "Game  93\n",
      "Game  94\n",
      "Game  95\n",
      "Game  96\n",
      "Game  97\n",
      "Game  98\n",
      "Game  99\n",
      "Game  100\n",
      "Alpha-Beta AI vs Random Player\n",
      "\n",
      "AI Wins: 97\n",
      "Random Player Wins: 2\n",
      "Ties: 1\n",
      "Average Turns: 39.33\n"
     ]
    }
   ],
   "source": [
    "# Simulate 100 games with AlphaBeta AI\n",
    "sim_games_AlphaBeta(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
